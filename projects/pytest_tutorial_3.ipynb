{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytest Tutorial - Part III\n",
    "# Welcome to the third Pytest Talk!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My name is Jack Camier, Data Scientist and Python Developer\n",
    "## Found below is a link to the first two talks of this series:\n",
    "https://github.com/jcamier/pytest-docker/blob/master/projects/pytest_tutorial.ipynb\n",
    "\n",
    "https://github.com/jcamier/pytest-docker/blob/master/projects/pytest_tutorial_2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspiration for this talk is based on Brian Okken's book, \"Python Testing with pytest\"\n",
    "https://pragprog.com/book/bopytest/python-testing-with-pytest\n",
    "# Brian Okken has a great podcast dedicated to testing with python called Test & Code:\n",
    "https://testandcode.com/\n",
    "# Also, special thanks to Christopher Prohm who created a package to run pytest in Jupyter Notebooks called ipytest\n",
    "https://github.com/chmp/ipytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section we will be focusing on fixtures and scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we need to import the ipytest package and its magic methods that allows us to use pytest in a Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytest\n",
    "import ipytest\n",
    "import ipytest.magics\n",
    "# Enable ipython AST transforms to rewrite asserts, defaults to False. Discussed in my last talk why.\n",
    "ipytest.config.rewrite_asserts = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name of the workbook, so pytest knows where to run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__file__ = \"pytest_tutorial_3.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR_DIR_FOR_PYTEST_TUTORIAL_3 = \"/Users/jacquescamier/DFW_Python_Talks/pytest_series\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminders:\n",
    "## Test files should be named test_something.py or something_test.py. \n",
    "## Test methods and functions should be named test_something. \n",
    "## Test classes should be named TestSomething.\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixtures are functions that are run by pytest before (sometimes after) the actual test functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fixtures.gif\" width=\"400\"/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<img src=\"../images/fixtures.gif\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"The code in the fixture can do whatever you want it to. You can use fixtures to get a data set for the tests to work on. You can use fixtures to get a system into a known state before running a test. Fixtures are also used to get data ready for multiple tests.\"\n",
    "\n",
    "- Okken, Brian. Python Testing with pytest: Simple, Rapid, Effective, and Scalable . Pragmatic Bookshelf. Kindle Edition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The @pytest.fixture() decorator is used to tell pytest that a function is a fixture. When you include the fixture name in the parameter list of a test function, pytest knows to run it before running the test.\n",
    "\n",
    "# Let's do a quick example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use ipytest magic commands to run pytest in jupyter notebook. ipytest.clean_tests() clears any previously defined tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipytest.clean_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@pytest.fixture()\n",
    "def set_data():\n",
    "    return 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F                                                                        [100%]\n",
      "=================================== FAILURES ===================================\n",
      "________________________________ test_set_data _________________________________\n",
      "\n",
      "set_data = 50\n",
      "\n",
      "    def test_set_data(set_data):\n",
      ">       assert set_data == 49\n",
      "E       assert 50 == 49\n",
      "E         -50\n",
      "E         +49\n",
      "\n",
      "<ipython-input-7-e5a6e4e81ad5>:4: AssertionError\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -qq\n",
    "\n",
    "# Create failing test\n",
    "def test_set_data(set_data):\n",
    "    assert set_data == 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                        [100%]\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -qq\n",
    "\n",
    "# Create passing test\n",
    "def test_set_data(set_data):\n",
    "    assert set_data == 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do another fixture example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipytest.clean_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test fixture of a dictionary function\n",
    "@pytest.fixture\n",
    "def dict_list():\n",
    "    return [\n",
    "        dict(a='a', b=3),\n",
    "        dict(a='c', b=1),\n",
    "        dict(a='b', b=2),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                        [100%]\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -qq\n",
    "\n",
    "# Pass the fixture function to the test function\n",
    "def test_sorted__key_example_1(dict_list):\n",
    "    assert sorted(dict_list, key=lambda d: d['a']) == [\n",
    "        dict(a='a', b=3),\n",
    "        dict(a='b', b=2),\n",
    "        dict(a='c', b=1),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytest fixtures are one of the core features that make pytest stand out above other test frameworks\n",
    "\n",
    "## *side note fixtures in pytest are not the same as fixtures in Django. In Django a fixture normally means to get some initial data loaded into a database at the start of the application.\n",
    "\n",
    "# You can put fixtures into individual test files, but to share fixtures among multiple test files, then you need to use a conftest.py file.\n",
    "\n",
    "# For today's talk, I will not be creating a conftest.py since all the tests will be done in this jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixtures include an optional parameter called scope. This controls how often fixtures get set up or torn down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/scope.png\" width=\"200\"/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<img src=\"../images/scope.png\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible fixture values of scope are: function, class, module, package or session. The default scope is function\n",
    "\n",
    "# scope='function'\n",
    "## Run once per test function. The setup portion is run before each test using the fixture. The teardown portion is run after each test using the fixture. This is the default scope used when no scope parameter is specified.\n",
    "\n",
    "# scope='class'\n",
    "## Run once per test class, regardless of how many test methods are in the class.\n",
    "\n",
    "# scope='module'\n",
    "## Run once per module, regardless of how many test functions or methods or other fixtures in the module use it.\n",
    "\n",
    "# scope='session'\n",
    "## Run once per session. All test methods and functions using a fixture of session scope share one setup and teardown call.\n",
    "\n",
    "- Okken, Brian. Python Testing with pytest: Simple, Rapid, Effective, and Scalable . Pragmatic Bookshelf. Kindle Edition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I created the above mentioned fixture and test in a file called test_dict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/test_dict_screenshot.png\" width=\"600\"/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<img src=\"../images/test_dict_screenshot.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the \"pytest --setup-show\" command argument, we can see how:\n",
    "## our test performed\n",
    "## the setup\n",
    "## the fixture that is being used\n",
    "## and the teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform darwin -- Python 2.7.14, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\r\n",
      "rootdir: /Users/jacquescamier/DFW_Python_Talks/pytest_series, inifile:\r\n",
      "\u001b[1m\r",
      "collecting 0 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 1 item                                                               \u001b[0m\u001b[1m\r",
      "collected 1 item                                                                \u001b[0m\r\n",
      "\r\n",
      "test_dict.py \r\n",
      "      SETUP    F dict_list\r\n",
      "        test_dict.py::test_sorted__key_example_1 (fixtures used: dict_list).\r\n",
      "      TEARDOWN F dict_list\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.01 seconds ===========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest --setup-show test_dict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's test a Django web app that is using Reactjs with pytest\n",
    "## The source code is found here:\n",
    "https://github.com/jcamier/pytest-django-react"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.babelrc',\n",
       " 'frontend',\n",
       " 'leads',\n",
       " 'node_modules',\n",
       " 'db.sqlite3',\n",
       " 'webpack.config.js',\n",
       " 'README.md',\n",
       " '.gitignore',\n",
       " 'package-lock.json',\n",
       " 'package.json',\n",
       " 'links',\n",
       " 'manage.py',\n",
       " '.git',\n",
       " 'leadmanager']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the global DJANGO_APP_DIR var to your directory\n",
    "DJANGO_APP_DIR = \"/Users/jacquescamier/PycharmProjects/django-react-app/leadmanager\"\n",
    "os.chdir(DJANGO_APP_DIR)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go to Django root directory and run python manage.py runserver\n",
    "http://127.0.0.1:8000/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's add a lead message in our app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This was built using Django rest_framework\n",
    "https://www.django-rest-framework.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Django rest_framework comes with built in REST features\n",
    "# Let's add a lead using the Django built in POST functionality\n",
    "## We can see the functionality by going to the link below\n",
    "http://127.0.0.1:8000/api/leads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipytest.clean_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(YOUR_DIR_FOR_PYTEST_TUTORIAL_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"id\":1,\"name\":\"John Doe\",\"email\":\"jdoe@gmail.com\",\"message\":\"Please contact John\",\"created_at\":\"2019-06-04T12:51:50.969056Z\"},{\"id\":2,\"name\":\"Sam Smith\",\"email\":\"sam@gmail.com\",\"message\":\"Please contact Bill\",\"created_at\":\"2019-06-04T12:52:56.896960Z\"},{\"id\":5,\"name\":\"Chris Cram\",\"email\":\"chris@gmail.com\",\"message\":\"Chris follow up with Sam\",\"created_at\":\"2019-06-06T00:44:01.151338Z\"},{\"id\":6,\"name\":\"George TheSalesman\",\"email\":\"george@gmail.com\",\"message\":\"George follow up with Chris on a car\",\"created_at\":\"2019-06-06T12:40:29.124993Z\"}]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use requests to do a simple get call\n",
    "import requests\n",
    "url = \"http://127.0.0.1:8000/api/leads/\"\n",
    "r = requests.get(url)\n",
    "\n",
    "r.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipytest.clean_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We could make the url a fixture\n",
    "@pytest.fixture\n",
    "def assign_url():\n",
    "    return \"http://127.0.0.1:8000/api/leads/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                        [100%]\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -qq\n",
    "def test_http_response(assign_url):\n",
    "    assert assign_url == \"http://127.0.0.1:8000/api/leads/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay, so that test passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipytest.clean_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@pytest.fixture\n",
    "def assign_url():\n",
    "    return \"http://127.0.0.1:8000/api/leads/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F.                                                                       [100%]\n",
      "=================================== FAILURES ===================================\n",
      "____________________________ test_requests_get_fail ____________________________\n",
      "\n",
      "assign_url = 'http://127.0.0.1:8000/api/leads/'\n",
      "\n",
      "    def test_requests_get_fail(assign_url):\n",
      "        url = assign_url\n",
      "        r = requests.get(url)\n",
      "        requests_text = r.text\n",
      ">       assert requests_text is None\n",
      "E       assert '[{\"id\":1,\"name\":\"John Doe\",\"email\":\"jdoe@gmail.com\",\"message\":\"Please contact John\",\"created_at\":\"2019-06-04T12:51:50...mail\":\"george@gmail.com\",\"message\":\"George follow up with Chris on a car\",\"created_at\":\"2019-06-06T12:40:29.124993Z\"}]' is None\n",
      "\n",
      "<ipython-input-25-09f06fd2429b>:5: AssertionError\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -qq\n",
    "def test_requests_get_fail(assign_url):\n",
    "    url = assign_url\n",
    "    r = requests.get(url)\n",
    "    requests_text = r.text\n",
    "    assert requests_text is None\n",
    "    \n",
    "def test_requests_get(assign_url):\n",
    "    url = assign_url\n",
    "    r = requests.get(url)\n",
    "    requests_text = r.text\n",
    "    assert requests_text is not None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipytest.clean_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                        [100%]\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -qq\n",
    "def test_requests_http_status_code(assign_url):\n",
    "    url = assign_url\n",
    "    r = requests.get(url)\n",
    "    requests_status_code = r.status_code\n",
    "    assert requests_status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipytest.clean_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 2.7.14, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\n",
      "rootdir: /Users/jacquescamier/DFW_Python_Talks/pytest_series, inifile:\n",
      "collected 4 items                                                               \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "test_django_requests.py \n",
      "      SETUP    F assign_url\n",
      "        test_django_requests.py::test_http_response (fixtures used: assign_url).\n",
      "      TEARDOWN F assign_url\n",
      "      SETUP    F assign_url\n",
      "        test_django_requests.py::test_requests_get_fail (fixtures used: assign_url)F\n",
      "      TEARDOWN F assign_url\n",
      "      SETUP    F assign_url\n",
      "        test_django_requests.py::test_requests_get (fixtures used: assign_url).\n",
      "      TEARDOWN F assign_url\n",
      "      SETUP    F assign_url\n",
      "        test_django_requests.py::test_requests_http_status_code (fixtures used: assign_url).\n",
      "      TEARDOWN F assign_url\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[1m\u001b[31m____________________________ test_requests_get_fail ____________________________\u001b[0m\n",
      "\n",
      "assign_url = 'http://127.0.0.1:8000/api/leads/'\n",
      "\n",
      "\u001b[1m    def test_requests_get_fail(assign_url):\u001b[0m\n",
      "\u001b[1m        url = assign_url\u001b[0m\n",
      "\u001b[1m        r = requests.get(url)\u001b[0m\n",
      "\u001b[1m        requests_text = r.text\u001b[0m\n",
      "\u001b[1m>       assert requests_text is None\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert '[{\"id\":1,\"name\":\"John Doe\",\"email\":\"jdoe@gmail.com\",\"message\":\"Please contact John\",\"created_at\":\"2019-06-04T12:51:50...mail\":\"george@gmail.com\",\"message\":\"George follow up with Chris on a car\",\"created_at\":\"2019-06-06T12:40:29.124993Z\"}]' is None\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_django_requests.py\u001b[0m:18: AssertionError\n",
      "\u001b[1m\u001b[31m====================== 1 failed, 3 passed in 0.50 seconds ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest --setup-show test_django_requests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36 (pytest)",
   "language": "python",
   "name": "venv-pytest-dock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
